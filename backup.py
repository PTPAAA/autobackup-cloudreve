import os
import shutil
import datetime
import logging
import time
import schedule
import threading
import subprocess
import json
import sys
import re
import platform

# === ä¾èµ–åº“æ£€æŸ¥ ===
try:
    from tqdm import tqdm
except ImportError:
    print("âŒ ç¼ºå°‘ tqdm åº“ï¼è¯·è¿è¡Œ: pip install tqdm")
    time.sleep(5)
    sys.exit(1)

# === å…¨å±€é…ç½® ===
CONFIG_FILE = "config.json"
LOG_FILE = "backup_service.log"
current_config = {}

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(LOG_FILE, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# ==========================================
#      é…ç½®æ¨¡å—
# ==========================================

def save_config(cfg):
    with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
        json.dump(cfg, f, indent=4)
    global current_config
    current_config = cfg

def load_config():
    global current_config
    if not os.path.exists(CONFIG_FILE):
        current_config = run_setup_wizard()
    else:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            current_config = json.load(f)

def run_setup_wizard():
    print("\n" + "="*60)
    print(" ğŸ“¦ é€šç”¨æœ¬åœ°å¤‡ä»½å·¥å…· (å«å¼€å‘è€…å·¥å…·)")
    print("="*60 + "\n")

    src = input("è¯·è¾“å…¥[æºæ•°æ®]ç›®å½•è·¯å¾„ > ").strip().replace('"','')
    bk_root = input("è¯·è¾“å…¥[å¤‡ä»½å­˜æ”¾]ç›®å½•è·¯å¾„ > ").strip().replace('"','')
    
    if not os.path.exists(bk_root): 
        try: os.makedirs(bk_root)
        except: pass
    
    system_type = platform.system()
    if system_type == "Windows":
        sz_path = r"C:\Program Files\7-Zip\7z.exe"
    else:
        sz_path = "7z"

    if system_type == "Windows" and not os.path.exists(sz_path):
        sz_input = input("æœªæ£€æµ‹åˆ°é»˜è®¤è·¯å¾„ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ 7z.exe è·¯å¾„ > ").strip().replace('"','')
        if os.path.exists(sz_input): sz_path = sz_input

    cfg = {
        "source_dir": src,
        "backup_root_dir": bk_root,
        "7zip_path": sz_path,
        "volume_size": "1g",
        "schedule_time": "03:00",
        "compression_level": 3
    }
    
    save_config(cfg)
    return cfg

# ==========================================
#      å·¥å…·å‡½æ•°
# ==========================================

def get_size(path):
    total_size = 0
    if os.path.isfile(path):
        total_size = os.path.getsize(path)
    else:
        for dirpath, dirnames, filenames in os.walk(path):
            for f in filenames:
                fp = os.path.join(dirpath, f)
                try: total_size += os.path.getsize(fp)
                except: pass
    return total_size / 1024 / 1024

def copy_with_progress(src, dst):
    total = 0
    f_list = []
    
    if os.path.isfile(src):
        total = os.path.getsize(src)
        f_list.append((src, total))
        if not os.path.exists(dst): os.makedirs(dst)
    else:
        for r, _, fs in os.walk(src):
            for f in fs:
                fp = os.path.join(r, f)
                try:
                    s = os.path.getsize(fp)
                    total += s
                    f_list.append((fp, s))
                except: pass
        if not os.path.exists(dst): os.makedirs(dst)
    
    with tqdm(total=total, unit='B', unit_scale=True, unit_divisor=1024, desc="ğŸš€ å¤åˆ¶æ–‡ä»¶", ncols=80) as pbar:
        for fp, sz in f_list:
            if os.path.isfile(src):
                target = os.path.join(dst, os.path.basename(src))
            else:
                rel_path = os.path.relpath(fp, src)
                target = os.path.join(dst, rel_path)
            
            os.makedirs(os.path.dirname(target), exist_ok=True)
            try:
                with open(fp, 'rb') as fsrc, open(target, 'wb') as fdst:
                    while True:
                        buf = fsrc.read(1024*1024) 
                        if not buf: break
                        fdst.write(buf)
                        pbar.update(len(buf))
                shutil.copystat(fp, target)
            except Exception as e:
                logging.error(f"Copy error {fp}: {e}")
                pbar.update(sz)

def compress_with_progress(cmd):
    cmd.append("-bsp1")
    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True, bufsize=1)
    
    print("ğŸ“¦ æ­£åœ¨å‹ç¼©...")
    with tqdm(total=100, unit="%", desc="ğŸ”¨ å‹ç¼©è¿›åº¦", ncols=80, colour='green') as pbar:
        curr = 0
        for line in p.stdout:
            m = re.search(r'\s(\d+)%', line)
            if m:
                val = int(m.group(1))
                if val > curr:
                    pbar.update(val - curr)
                    curr = val
    return p.wait()

def verify_archive(seven_zip_path, archive_path):
    print(f"ğŸ” æ ¡éªŒå®Œæ•´æ€§: {os.path.basename(archive_path)} ...")
    cmd = [seven_zip_path, "t", archive_path, "-bsp1", "-y"]
    try:
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True, bufsize=1)
        with tqdm(total=100, unit="%", desc="ğŸ›¡ï¸ æ ¡éªŒè¿›åº¦", ncols=80, colour='cyan') as pbar:
            curr = 0
            for line in p.stdout:
                m = re.search(r'\s(\d+)%', line)
                if m:
                    val = int(m.group(1))
                    if val > curr:
                        pbar.update(val - curr)
                        curr = val
        ret_code = p.wait()
        return ret_code == 0
    except Exception as e:
        logging.error(f"Verification error: {e}")
        return False

# ==========================================
#      å¼€å‘è€…å·¥å…·æ¨¡å— (Dev Tools)
# ==========================================

def run_test_mode():
    """å‹åŠ›æµ‹è¯•æ¨¡å¼ï¼šç”Ÿæˆéšæœºæ•°æ®å¹¶è·‘ä¸€éæµç¨‹"""
    print("\n" + "="*50)
    print("ğŸ§ª å‹åŠ›æµ‹è¯•æ¨¡å¼ (Dev Tools)")
    print("="*50)
    
    gb_input = input("è¯·è¾“å…¥æµ‹è¯•æ•°æ®å¤§å°(GB) [é»˜è®¤ 0.5]: ").strip()
    try: target_gb = float(gb_input) if gb_input else 0.5
    except: target_gb = 0.5

    # 1. ç”Ÿæˆéšæœºæµ‹è¯•æ•°æ®
    test_src = os.path.join(os.getcwd(), "TEMP_TEST_DATA")
    if not os.path.exists(test_src): os.makedirs(test_src)
    
    f_path = os.path.join(test_src, "random_garbage.dat")
    chunk_size = 5 * 1024 * 1024 # 5MB chunk
    total_chunks = int(target_gb * 1024**3 / chunk_size)
    if total_chunks == 0: total_chunks = 1
    
    print(f"ğŸ”¨ æ­£åœ¨ç”Ÿæˆ {target_gb}GB éšæœºæ•°æ®...")
    with open(f_path, 'wb') as f, tqdm(total=total_chunks, unit="å—", desc="ç”Ÿæˆæ•°æ®", ncols=80) as pbar:
        random_bytes = os.urandom(chunk_size) # å¤ç”¨åŒä¸€å—å†…å­˜ï¼Œé€Ÿåº¦æ›´å¿«
        for _ in range(total_chunks):
            f.write(random_bytes)
            pbar.update(1)
            
    # 2. ä¸´æ—¶æ›¿æ¢é…ç½®
    original_src = current_config["source_dir"]
    current_config["source_dir"] = test_src
    
    print(f"\nğŸš€ å¼€å§‹æ¨¡æ‹Ÿå¤‡ä»½æµç¨‹...")
    try:
        backup_job(is_test=True)
        print("\nâœ… æµ‹è¯•æµç¨‹ç»“æŸ")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
    finally:
        # 3. æ¢å¤ç°åœº
        current_config["source_dir"] = original_src
        print("ğŸ§¹ æ¸…ç†ä¸´æ—¶æµ‹è¯•æºæ–‡ä»¶...")
        try: shutil.rmtree(test_src)
        except Exception as e: print(f"æ¸…ç†å¤±è´¥: {e}")

def run_deltest():
    """æ¸…ç†æ‰€æœ‰ _TEST ç»“å°¾çš„å¤‡ä»½æ–‡ä»¶å¤¹"""
    print("\n" + "="*50)
    print("ğŸ—‘ï¸  æ¸…ç†æµ‹è¯•æ®‹ç•™ (deltest)")
    print("="*50)
    
    backup_root = current_config.get("backup_root_dir")
    if not backup_root or not os.path.exists(backup_root):
        print("å¤‡ä»½ç›®å½•æ— æ•ˆ")
        return

    count = 0
    for d in os.listdir(backup_root):
        # åŒ¹é…æ—¥æœŸ_TEST æˆ–è€… source_Split_TEST ç­‰æ¨¡å¼
        if "_TEST" in d:
            full_path = os.path.join(backup_root, d)
            if os.path.isdir(full_path):
                print(f"   ğŸ”¥ åˆ é™¤: {d}")
                try: 
                    shutil.rmtree(full_path)
                    count += 1
                except Exception as e: print(f"åˆ é™¤å¤±è´¥: {e}")
    
    if count == 0:
        print("   (æœªå‘ç°æµ‹è¯•æ®‹ç•™)")
    else:
        print(f"\nâœ… å…±æ¸…ç† {count} ä¸ªæµ‹è¯•ç›®å½•")

# ==========================================
#      æ ¸å¿ƒä»»åŠ¡é€»è¾‘
# ==========================================

def backup_job(is_test=False):
    cfg = current_config
    if not cfg:
        logging.error("No config loaded.")
        return

    start_time = datetime.datetime.now()
    tag = "[ğŸ§ªæµ‹è¯•]" if is_test else "[ğŸš€æ­£å¼]"
    logging.info(f"{tag} Backup task started")
    print(f"\nâ° {tag} ä»»åŠ¡å¯åŠ¨ [{start_time.strftime('%H:%M:%S')}]")

    # å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œæ—¥æœŸæ–‡ä»¶å¤¹åŠ åç¼€
    d_str = start_time.strftime("%y.%m.%d")
    if is_test: d_str += "_TEST"
    
    t_str = start_time.strftime("%H%M%S")
    
    # 1. å‡†å¤‡ç›®å½•ç»“æ„
    daily_root = os.path.join(cfg["backup_root_dir"], d_str)
    raw_dir = os.path.join(daily_root, f"temp_raw_{t_str}")
    
    source_path = cfg["source_dir"]
    source_name = os.path.basename(source_path.rstrip("\\/"))
    if not source_name: source_name = "backup"
    
    # 2. ä¼°ç®—å¤§å°å¹¶å†³å®šç­–ç•¥
    if not is_test: print("ğŸ“ è®¡ç®—æºæ–‡ä»¶å¤§å°...")
    total_mb = get_size(source_path)
    if not is_test: print(f"   æºå¤§å°: {total_mb:.2f} MB")
    
    is_large_file = total_mb >= 1000 
    
    if is_large_file:
        if not is_test: print("   âš–ï¸  ç­–ç•¥: å¤§æ–‡ä»¶ -> åˆ†å·å‹ç¼©")
        archive_store_dir = os.path.join(daily_root, f"{source_name}_Split_{t_str}")
        archive_name = os.path.join(archive_store_dir, f"{source_name}.7z")
        split_arg = f"-v{cfg['volume_size']}" 
    else:
        if not is_test: print("   âš–ï¸  ç­–ç•¥: å°æ–‡ä»¶ -> å•æ–‡ä»¶å½’æ¡£")
        archive_store_dir = daily_root
        archive_name = os.path.join(archive_store_dir, f"{source_name}_{t_str}.7z")
        split_arg = "-v999g" 

    try:
        os.makedirs(archive_store_dir, exist_ok=True)
        os.makedirs(raw_dir, exist_ok=True)
        
        # æ­¥éª¤ 1: å¤åˆ¶ (é•œåƒ)
        copy_with_progress(source_path, raw_dir)
        
        # æ­¥éª¤ 2: å‹ç¼©
        cmd = [
            cfg["7zip_path"], "a", archive_name, 
            os.path.join(raw_dir, "*"),
            split_arg, 
            f"-mx={cfg['compression_level']}", 
            "-mmt=on", "-y"
        ]
        
        if compress_with_progress(cmd) == 0:
            if not is_test: print("âœ… å½’æ¡£æˆåŠŸï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            try: shutil.rmtree(raw_dir)
            except: pass
            
            # æ­¥éª¤ 3: æ ¡éªŒ
            verify_target = archive_name
            if is_large_file and not os.path.exists(archive_name) and os.path.exists(archive_name + ".001"):
                verify_target = archive_name + ".001"
            
            if verify_archive(cfg["7zip_path"], verify_target):
                duration = (datetime.datetime.now() - start_time).seconds
                if not is_test:
                    print(f"ğŸ“¦ å¤‡ä»½å®Œæˆ! è€—æ—¶: {duration} ç§’")
                logging.info(f"Backup success. Duration: {duration}s")
            else:
                logging.error("Verification failed.")
                print("âŒ æ ¡éªŒå¤±è´¥")
        else:
            logging.error("7-Zip failed.")
            print("âŒ å‹ç¼©è¿‡ç¨‹å‡ºé”™")

    except Exception as e:
        logging.error(f"Critical error: {e}", exc_info=True)
        print(f"âŒ å‘ç”Ÿå¼‚å¸¸: {e}")
    finally:
        if not is_test: print("\næŒ‡ä»¤ > ", end="")

# ==========================================
#      ä¸»ç¨‹åº
# ==========================================

def run_scheduler_thread():
    schedule.every().day.at(current_config["schedule_time"]).do(backup_job, is_test=False)
    while True:
        schedule.run_pending()
        time.sleep(1)

if __name__ == "__main__":
    setup_logging()
    load_config()
    
    t = threading.Thread(target=run_scheduler_thread, daemon=True)
    t.start()
    
    print("\n" + "="*50)
    print(" ğŸ“¦ é€šç”¨æœ¬åœ°å¤‡ä»½å·¥å…· (Local Auto-Backup)")
    print("    å«å¼€å‘æµ‹è¯•å·¥å…·åŒ…")
    print(f"  - æºç›®å½•: {current_config.get('source_dir', 'æœªè®¾ç½®')}")
    print(f"  - å¤‡ä»½ä»“: {current_config.get('backup_root_dir', 'æœªè®¾ç½®')}")
    print("-" * 50)
    print(" å¸¸ç”¨æŒ‡ä»¤:")
    print("   [backup]  ç«‹å³å¤‡ä»½")
    print("   [test]    å‹åŠ›æµ‹è¯• (ç”Ÿæˆéšæœºæ•°æ®éªŒè¯æµç¨‹)")
    print("   [deltest] æ¸…ç†æµ‹è¯•äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶å¤¹")
    print("   [setup]   é‡æ–°é…ç½®")
    print("   [exit]    é€€å‡º")
    print("="*50 + "\n")

    while True:
        try:
            cmd = input("æŒ‡ä»¤ > ").strip().lower()
            if cmd == 'backup':
                backup_job(is_test=False)
            elif cmd == 'test':
                run_test_mode()
            elif cmd == 'deltest':
                run_deltest()
            elif cmd == 'setup': 
                run_setup_wizard()
                load_config()
                print("âš ï¸ é…ç½®å·²æ›´æ–°ï¼Œå»ºè®®é‡å¯ç¨‹åºã€‚")
            elif cmd == 'exit':
                sys.exit(0)
        except KeyboardInterrupt:
            sys.exit(0)
        except Exception as e:
            print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
